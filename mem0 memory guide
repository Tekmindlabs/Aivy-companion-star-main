
python -c "import mem0ai; print(mem0ai.__file__)"


add path 

$env:PYTHONPATH = "$env:PYTHONPATH;D:\Aivy\Aivy-Tutor\lib\memory\python"


# Comprehensive Guide for Mem0 Implementation in Aivy Tutor System

## 1. Overview
Mem0 is an intelligent memory layer designed to enhance AI assistants by retaining user preferences and traits across interactions. This guide provides essential information for implementing Mem0 in the Aivy Tutor system.

## 2. Core Components

### 2.1 Memory Management
```typescript
// Memory Service Configuration
interface MemoryConfig {
  vector_store: {
    provider: "qdrant";
    config: {
      collection_name: string;
      host: string;
      port: number;
      embedding_model_dims: number;
    };
  };
  llm?: {
    provider: string;
    config: {
      model: string;
      temperature: number;
      max_tokens: number;
    };
  };
  embedder: {
    provider: string;
    config: {
      model: string;
    };
  };
}
```

### 2.2 Memory Bridge Implementation
```typescript
// D:\Aivy\Aivy-Tutor\lib\memory\bridge.ts
export class Mem0Bridge {
  private pythonProcess: ChildProcess | null = null;

  async initialize() {
    // Initialize Python bridge
  }

  async addMemory(content: string, userId: string, metadata?: any) {
    // Add memory implementation
  }

  async searchMemories(query: string, userId: string, limit: number = 5) {
    // Search memories implementation
  }

  async deleteMemory(userId: string, memoryId: string) {
    // Delete memory implementation
  }
}
```

## 3. Integration Components

### 3.1 Memory Client
```typescript
// mem0-client.ts
export interface Mem0Client {
  add(content: string, userId: string, metadata?: Record<string, any>): Promise<any>;
  search(query: string, userId: string, limit?: number): Promise<any>;
  delete(userId: string, memoryId: string): Promise<any>;
}

class DefaultMem0Client implements Mem0Client {
  private bridge: Mem0Bridge;

  constructor() {
    this.bridge = new Mem0Bridge();
  }
  
  // Implementation methods
}
```

### 3.2 Memory Service
```typescript
// memory-service.ts
export class MemoryService {
  private client: Mem0Client;

  constructor() {
    this.client = getMem0Client();
  }

  async addMemory(content: MemoryContent): Promise<void> {
    // Memory addition logic
  }

  async searchMemories(query: string, userId: string, limit?: number): Promise<any> {
    // Memory search logic
  }
}
```

## 4. Configuration Settings

### 4.1 Default Configuration
```typescript
const defaultConfig = {
  vector_store: {
    provider: "qdrant",
    config: {
      collection_name: "aivy_memories",
      host: "localhost",
      port: 6333,
      embedding_model_dims: 1536
    }
  },
  embedder: {
    provider: "openai",
    config: {
      model: "text-embedding-3-large"
    }
  }
};
```

### 4.2 Environment Variables
```env
OPENAI_API_KEY=your_api_key
MEM0_API_KEY=your_mem0_api_key
```

## 5. Memory Processing

### 5.1 Fact Extraction
```python
def _extract_facts(self, content):
    """Extract relevant facts from message content."""
    # Remove conversational fillers
    content = content.replace("Hi, ", "").replace("Hello, ", "")
    
    # Extract preferences and facts
    if "I am" in content or "I'm" in content:
        content = content.replace("I am ", "").replace("I'm ", "")
    
    if "I like" in content or "I love" in content:
        content = content.replace("I like ", "Likes ").replace("I love ", "Loves ")
    
    if "I don't" in content or "I do not" in content:
        content = content.replace("I don't ", "Does not ").replace("I do not ", "Does not ")
        
    return content.strip()
```

## 6. Usage Examples

### 6.1 Basic Memory Operations
```typescript
// Initialize memory service
const memoryService = new MemoryService();

// Add memory
await memoryService.addMemory({
  userId: "user123",
  content: "User prefers visual learning methods",
  metadata: { type: "learning_preference" }
});

// Search memories
const memories = await memoryService.searchMemories(
  "learning preferences",
  "user123",
  5
);
```

### 6.2 Integration with Chat
```typescript
// In chat route handler
export async function POST(req: Request) {
  const { messages, userId } = await req.json();
  
  // Search relevant memories
  const relevantMemories = await memoryService.searchMemories(
    messages[messages.length - 1].content,
    userId
  );

  // Process chat with context
  const response = await processChat(messages, relevantMemories);
  
  // Store new memory
  await memoryService.addMemory({
    userId,
    content: messages[messages.length - 1].content,
    metadata: { type: "chat_interaction" }
  });

  return NextResponse.json(response);
}
```

## 7. Best Practices

1. **Memory Storage**:
   - Store concise, relevant facts instead of complete conversations
   - Focus on user preferences, traits, and important information
   - Use metadata to categorize different types of memories

2. **Memory Retrieval**:
   - Implement proper error handling for failed memory operations
   - Use appropriate search limits to prevent overwhelming responses
   - Consider relevance scores when using retrieved memories

3. **System Integration**:
   - Initialize the memory bridge early in the application lifecycle
   - Implement proper cleanup for Python bridge processes
   - Use appropriate error handling for cross-process communication

4. **Performance Optimization**:
   - Cache frequently accessed memories
   - Implement proper indexing in the vector store
   - Use appropriate batch sizes for memory operations

This guide serves as a comprehensive reference for implementing and maintaining Mem0 in the Aivy Tutor system. Keep it updated as the system evolves and new features are added.